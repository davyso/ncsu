{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/DaveSomo/anaconda3/envs/deeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "%matplotlib inline\n",
    "from decimal import Decimal\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,Normalizer, MinMaxScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('C:\\\\Users\\\\lengada1\\\\NCSU\\\\DC_ten_skus.csv')\n",
    "df=pd.read_csv('./DC_ten_skus.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.weekday_name\n",
    "day_dummy=pd.get_dummies(df.Day)\n",
    "df=pd.concat([df,day_dummy],axis=1)\n",
    "df.drop(['Day','Date'],inplace=True,axis=1)\n",
    "\n",
    "y=df['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open  Promo  SchoolHoliday  Year  Month  Friday  Monday  Saturday  Sunday  \\\n",
       "0     0      0             10  2013      1       0       0         0       0   \n",
       "1    10      0             10  2013      1       0       0         0       0   \n",
       "2    10      0              8  2013      1       0       0         0       0   \n",
       "3    10      0              8  2013      1       1       0         0       0   \n",
       "4    10      0              1  2013      1       0       0         1       0   \n",
       "\n",
       "   Thursday  Tuesday  Wednesday  \n",
       "0         0        1          0  \n",
       "1         0        0          1  \n",
       "2         1        0          0  \n",
       "3         0        0          0  \n",
       "4         0        0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(['id','DayOfWeek','Customers','Sales'],inplace=False,axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs in range(1,8):\n",
    "    X[\"Sales_T\"+str(obs)]=df['Sales'].shift(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Sales_T1</th>\n",
       "      <th>Sales_T2</th>\n",
       "      <th>Sales_T3</th>\n",
       "      <th>Sales_T4</th>\n",
       "      <th>Sales_T5</th>\n",
       "      <th>Sales_T6</th>\n",
       "      <th>Sales_T7</th>\n",
       "      <th>Mov_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43727.0</td>\n",
       "      <td>55606.0</td>\n",
       "      <td>52848.0</td>\n",
       "      <td>60436.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72552.0</td>\n",
       "      <td>89391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43727.0</td>\n",
       "      <td>55606.0</td>\n",
       "      <td>52848.0</td>\n",
       "      <td>60436.0</td>\n",
       "      <td>53508.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64297.0</td>\n",
       "      <td>72552.0</td>\n",
       "      <td>89391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43727.0</td>\n",
       "      <td>55606.0</td>\n",
       "      <td>52848.0</td>\n",
       "      <td>54060.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64112.0</td>\n",
       "      <td>64297.0</td>\n",
       "      <td>72552.0</td>\n",
       "      <td>89391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43727.0</td>\n",
       "      <td>55606.0</td>\n",
       "      <td>55669.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65006.0</td>\n",
       "      <td>64112.0</td>\n",
       "      <td>64297.0</td>\n",
       "      <td>72552.0</td>\n",
       "      <td>89391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43727.0</td>\n",
       "      <td>57012.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open  Promo  SchoolHoliday  Year  Month  Friday  Monday  Saturday  Sunday  \\\n",
       "0    10     10              1  2013      1       0       0         0       0   \n",
       "1    10     10              1  2013      1       0       0         0       0   \n",
       "2    10     10              1  2013      1       0       0         0       0   \n",
       "3    10     10              1  2013      1       1       0         0       0   \n",
       "4    10      0              0  2013      1       0       0         1       0   \n",
       "\n",
       "   Thursday  Tuesday  Wednesday  Sales_T1  Sales_T2  Sales_T3  Sales_T4  \\\n",
       "0         0        1          0   89391.0       0.0   43727.0   55606.0   \n",
       "1         0        0          1   72552.0   89391.0       0.0   43727.0   \n",
       "2         1        0          0   64297.0   72552.0   89391.0       0.0   \n",
       "3         0        0          0   64112.0   64297.0   72552.0   89391.0   \n",
       "4         0        0          0   65006.0   64112.0   64297.0   72552.0   \n",
       "\n",
       "   Sales_T5  Sales_T6  Sales_T7       Mov_avg  \n",
       "0   52848.0   60436.0       0.0  43144.000000  \n",
       "1   55606.0   52848.0   60436.0  53508.571429  \n",
       "2   43727.0   55606.0   52848.0  54060.142857  \n",
       "3       0.0   43727.0   55606.0  55669.285714  \n",
       "4   89391.0       0.0   43727.0  57012.142857  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Mov_avg']=df['Sales'].rolling( window=7).mean().shift(1) \n",
    "y=y[7:]\n",
    "X=X[7:]\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = preprocessing.StandardScaler().fit(X)\n",
    "X = std.transform(X)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=2\n",
    "\n",
    "RF=RandomForestRegressor( n_estimators=1000,max_depth=10,max_features=14);\n",
    "rf_models=[];\n",
    "rf_models=(cross_val_score(RF,X,y,cv=cv, scoring ='mean_absolute_error').mean().round(0) )\n",
    "\n",
    "\n",
    "GB=ensemble.GradientBoostingRegressor(n_estimators= 1000,max_depth= 8, max_features=14,\n",
    "          learning_rate= 0.01, loss= 'ls');\n",
    "gb_models=[];\n",
    "gb_models=(cross_val_score(GB,X,y,cv=cv, scoring ='mean_absolute_error').mean().round(0)  )\n",
    "   \n",
    "\n",
    "XG=xgb.XGBRegressor(n_estimators= 900,learning_rate =0.01, max_depth=6,gamma=2)\n",
    "xg_models=[]\n",
    "xg_models=(cross_val_score(XG,X,y,cv=cv, scoring ='mean_absolute_error').mean().round(0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLP():\n",
    "    mlp=models.Sequential()\n",
    "    mlp.add(Dense(20, input_dim=X.shape[1], activation='relu'))\n",
    "    #mlp.add(Dense(20, activation='relu'))\n",
    "    mlp.add(Dense(30, activation='relu'))\n",
    "    mlp.add(Dense(10, activation='relu'))    \n",
    "    mlp.add(Dense(1, activation='relu'))\n",
    "    mlp.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "    return mlp\n",
    "\n",
    "MLP = KerasRegressor(build_fn=create_MLP,\n",
    "                               epochs=300,\n",
    "                               batch_size=20,\n",
    "                               verbose=0)\n",
    "\n",
    "mlp_models=[]\n",
    "mlp_models=(cross_val_score(MLP,X,y,cv=cv).mean().round(0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "(\"The kernel, 1**2 * ExpSineSquared(length_scale=1, periodicity=3), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '5-th leading minor of the array is not positive definite')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fcfd38d9fea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#which can adapt to step-wise data (Every Sunday = 0 sales).  Read you can use ensemble GPRs. Please research.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgpr_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgpr_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_indices_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             exc.args = (\"The kernel, %s, is not returning a \"\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0;32m---> 91\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.5/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n\u001b[0;32m---> 40\u001b[0;31m                           \"definite\" % info)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         raise ValueError('LAPACK reported an illegal value in {}-th argument'\n",
      "\u001b[0;31mLinAlgError\u001b[0m: (\"The kernel, 1**2 * ExpSineSquared(length_scale=1, periodicity=3), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '5-th leading minor of the array is not positive definite')"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "kernels = [1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "           1.0 * RationalQuadratic(length_scale=1.0),\n",
    "           1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0,\n",
    "                                length_scale_bounds=(0.1, 10.0),\n",
    "                                periodicity_bounds=(1.0, 10.0)),\n",
    "           1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0),\n",
    "                        nu=1.5)]\n",
    "\n",
    "n_restarts_optimizer=10\n",
    "\n",
    "GPR=GaussianProcessRegressor(kernel=kernels[2], n_restarts_optimizer=n_restarts_optimizer)  \n",
    "#You can swap out between 4 kernels.  Need to find a kernel and parameterization of that kernel \n",
    "#which can adapt to step-wise data (Every Sunday = 0 sales).  Read you can use ensemble GPRs. Please research.\n",
    "gpr_models=[]\n",
    "gpr_models=(cross_val_score(GPR,X,y,cv=cv, scoring='mean_absolute_error').mean().round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>XG</th>\n",
       "      <th>GPR</th>\n",
       "      <th>Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29336.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>10420.0</td>\n",
       "      <td>XG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MLP      RF      GB      XG      GPR Best\n",
       "0  29336.0  3306.0  3220.0  3208.0  10420.0   XG"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae=-pd.DataFrame(np.column_stack((mlp_models,rf_models,gb_models,xg_models)) )\n",
    "# mae=mae.rename(columns = {0:'MLP',1:'RF',2:'GB',3:'XG'})\n",
    "# best=mae.idxmin(axis=1)\n",
    "# best.astype('category')\n",
    "# mae[\"Best\"]=best\n",
    "# mae\n",
    "\n",
    "# Add GRP to summary\n",
    "mae=-pd.DataFrame(np.column_stack((mlp_models,rf_models,gb_models,xg_models,gpr_models)) )\n",
    "mae=mae.rename(columns = {0:'MLP',1:'RF',2:'GB',3:'XG',4:\"GPR\"})\n",
    "best=mae.idxmin(axis=1)\n",
    "best.astype('category')\n",
    "mae[\"Best\"]=best\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same models as above, but configured here to predict over entire X (935 days)\n",
    "def RF_final(X, y):\n",
    "    tree=RF\n",
    "    tree.fit(X,y)\n",
    "    pred=tree.predict(X)\n",
    "    pred=pd.DataFrame(pred)\n",
    "    pred.reset_index(drop=True, inplace=True)\n",
    "    pred=pred.rename(columns = {0:'RF'})\n",
    "    return (pred, tree)\n",
    "\n",
    "def MLP_final(X,y):\n",
    "    model = MLP\n",
    "    model.fit(X,y)\n",
    "    pred=model.predict(X)\n",
    "    pred=pd.DataFrame(pred)\n",
    "    pred.reset_index(drop=True, inplace=True)\n",
    "    pred=pred.rename(columns = {0:'MLP'})\n",
    "    return (pred, model)\n",
    "\n",
    "def GB_final(X,y):\n",
    "    model = GB\n",
    "    model.fit(X,y)\n",
    "    prediction=model.predict(X)\n",
    "    pred=pd.DataFrame(prediction)\n",
    "    pred.reset_index(drop=True, inplace=True)\n",
    "    pred=pred.rename(columns = {0:'GB'})\n",
    "    return (pred, model)\n",
    "\n",
    "def XG_final(X,y):\n",
    "    model=XG\n",
    "    model.fit(X,y)\n",
    "    prediction=model.predict(X)\n",
    "    pred=pd.DataFrame(prediction)\n",
    "    pred.reset_index(drop=True, inplace=True)\n",
    "    pred=pred.rename(columns = {0:'XG'})\n",
    "    return (pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using aggregated SKU sales data, the best performing model is selected based on K-fold. \n",
    "#Then best model is used to predict full data set \n",
    "\n",
    "bm_dict={}\n",
    "for sku in range(0,1):        \n",
    "        if  mae[\"Best\"][0]==\"RF\":\n",
    "            bm_dict[sku]=RF_final(X,y);\n",
    "                    \n",
    "        elif mae[\"Best\"][0]==\"NN\":\n",
    "            bm_dict[sku]=MLP_final(X,y);\n",
    "                                \n",
    "        elif mae[\"Best\"][0]==\"GB\":\n",
    "            bm_dict[sku]=GB_final(X,y); \n",
    "                        \n",
    "        elif mae[\"Best\"][0]==\"XG\":\n",
    "            bm_dict[sku]=XG_final(X,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5717.818209</td>\n",
       "      <td>6301.653071</td>\n",
       "      <td>9865.725643</td>\n",
       "      <td>10153.291251</td>\n",
       "      <td>5602.367520</td>\n",
       "      <td>7176.216977</td>\n",
       "      <td>10341.561739</td>\n",
       "      <td>6505.311482</td>\n",
       "      <td>6302.959000</td>\n",
       "      <td>5714.657222</td>\n",
       "      <td>73681.562097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5510.298604</td>\n",
       "      <td>6512.066582</td>\n",
       "      <td>8556.524297</td>\n",
       "      <td>9330.420316</td>\n",
       "      <td>5765.830248</td>\n",
       "      <td>6921.244257</td>\n",
       "      <td>8090.852354</td>\n",
       "      <td>5673.728950</td>\n",
       "      <td>5184.818400</td>\n",
       "      <td>5539.029505</td>\n",
       "      <td>67084.813473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5079.047790</td>\n",
       "      <td>5460.737801</td>\n",
       "      <td>7735.243498</td>\n",
       "      <td>9324.782816</td>\n",
       "      <td>4944.436392</td>\n",
       "      <td>6314.656802</td>\n",
       "      <td>8066.825115</td>\n",
       "      <td>6234.547054</td>\n",
       "      <td>5388.263000</td>\n",
       "      <td>5616.178584</td>\n",
       "      <td>64164.719037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4855.066339</td>\n",
       "      <td>4907.510546</td>\n",
       "      <td>8600.125698</td>\n",
       "      <td>9873.201129</td>\n",
       "      <td>5069.712080</td>\n",
       "      <td>6927.614117</td>\n",
       "      <td>8099.700803</td>\n",
       "      <td>5206.362083</td>\n",
       "      <td>5703.361300</td>\n",
       "      <td>5606.811352</td>\n",
       "      <td>64849.465475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4848.817431</td>\n",
       "      <td>2609.258951</td>\n",
       "      <td>4299.631053</td>\n",
       "      <td>9935.107310</td>\n",
       "      <td>1835.048437</td>\n",
       "      <td>3765.943200</td>\n",
       "      <td>4538.281949</td>\n",
       "      <td>2510.754229</td>\n",
       "      <td>4922.026000</td>\n",
       "      <td>4541.323872</td>\n",
       "      <td>43806.192311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4364.450817</td>\n",
       "      <td>4004.262165</td>\n",
       "      <td>5161.439033</td>\n",
       "      <td>7940.504973</td>\n",
       "      <td>3824.709259</td>\n",
       "      <td>5972.879755</td>\n",
       "      <td>6844.887051</td>\n",
       "      <td>4286.980709</td>\n",
       "      <td>4508.520000</td>\n",
       "      <td>4817.428118</td>\n",
       "      <td>51726.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4031.301953</td>\n",
       "      <td>3947.826898</td>\n",
       "      <td>5158.895142</td>\n",
       "      <td>7462.205307</td>\n",
       "      <td>3727.959016</td>\n",
       "      <td>5616.944218</td>\n",
       "      <td>6807.330886</td>\n",
       "      <td>4192.341320</td>\n",
       "      <td>4212.599000</td>\n",
       "      <td>4569.376346</td>\n",
       "      <td>49726.780208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3944.842050</td>\n",
       "      <td>4649.660839</td>\n",
       "      <td>5124.796593</td>\n",
       "      <td>7195.689326</td>\n",
       "      <td>3997.489338</td>\n",
       "      <td>5247.771443</td>\n",
       "      <td>6372.850673</td>\n",
       "      <td>3895.344289</td>\n",
       "      <td>3837.493400</td>\n",
       "      <td>4551.669918</td>\n",
       "      <td>48817.607877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3894.189293</td>\n",
       "      <td>3881.791308</td>\n",
       "      <td>5029.780984</td>\n",
       "      <td>7370.564596</td>\n",
       "      <td>3713.124132</td>\n",
       "      <td>5554.787497</td>\n",
       "      <td>6780.353349</td>\n",
       "      <td>4827.428066</td>\n",
       "      <td>4421.266000</td>\n",
       "      <td>4520.857199</td>\n",
       "      <td>49994.142538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4245.188187</td>\n",
       "      <td>3914.496199</td>\n",
       "      <td>5753.720775</td>\n",
       "      <td>7714.182408</td>\n",
       "      <td>4080.789181</td>\n",
       "      <td>5715.102832</td>\n",
       "      <td>7574.897096</td>\n",
       "      <td>3990.749414</td>\n",
       "      <td>4977.212400</td>\n",
       "      <td>4764.123412</td>\n",
       "      <td>52730.461908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4983.633181</td>\n",
       "      <td>2532.131341</td>\n",
       "      <td>4116.094082</td>\n",
       "      <td>9505.201476</td>\n",
       "      <td>1778.062763</td>\n",
       "      <td>3646.093786</td>\n",
       "      <td>4818.921211</td>\n",
       "      <td>2425.080131</td>\n",
       "      <td>5132.261000</td>\n",
       "      <td>4502.695003</td>\n",
       "      <td>43440.174202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5744.192988</td>\n",
       "      <td>6577.690528</td>\n",
       "      <td>7323.494665</td>\n",
       "      <td>11638.913468</td>\n",
       "      <td>6713.288646</td>\n",
       "      <td>7280.665828</td>\n",
       "      <td>10721.421378</td>\n",
       "      <td>7750.308633</td>\n",
       "      <td>6943.394500</td>\n",
       "      <td>6657.925012</td>\n",
       "      <td>77351.295677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5223.222718</td>\n",
       "      <td>5930.723979</td>\n",
       "      <td>8106.196403</td>\n",
       "      <td>9930.915505</td>\n",
       "      <td>5657.912371</td>\n",
       "      <td>7011.165911</td>\n",
       "      <td>9260.975655</td>\n",
       "      <td>6376.083705</td>\n",
       "      <td>5284.628400</td>\n",
       "      <td>5405.284997</td>\n",
       "      <td>68187.109661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5362.314867</td>\n",
       "      <td>6181.119323</td>\n",
       "      <td>8337.048882</td>\n",
       "      <td>9310.429981</td>\n",
       "      <td>5723.656718</td>\n",
       "      <td>6988.189735</td>\n",
       "      <td>8047.107928</td>\n",
       "      <td>5940.518205</td>\n",
       "      <td>5022.631300</td>\n",
       "      <td>5270.986395</td>\n",
       "      <td>66184.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5163.339575</td>\n",
       "      <td>5152.720556</td>\n",
       "      <td>7665.836171</td>\n",
       "      <td>9095.553007</td>\n",
       "      <td>4884.909327</td>\n",
       "      <td>6215.657925</td>\n",
       "      <td>7918.644043</td>\n",
       "      <td>6436.209779</td>\n",
       "      <td>5071.469000</td>\n",
       "      <td>4981.103498</td>\n",
       "      <td>62585.443120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5257.620845</td>\n",
       "      <td>4781.019769</td>\n",
       "      <td>7538.104661</td>\n",
       "      <td>9534.606713</td>\n",
       "      <td>4964.245910</td>\n",
       "      <td>6586.677830</td>\n",
       "      <td>8398.576603</td>\n",
       "      <td>5148.807489</td>\n",
       "      <td>5526.992000</td>\n",
       "      <td>5377.504432</td>\n",
       "      <td>63114.156440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5379.716069</td>\n",
       "      <td>2459.275038</td>\n",
       "      <td>4088.689027</td>\n",
       "      <td>9704.708709</td>\n",
       "      <td>1711.137049</td>\n",
       "      <td>3568.620140</td>\n",
       "      <td>4415.173737</td>\n",
       "      <td>2419.843968</td>\n",
       "      <td>4963.051300</td>\n",
       "      <td>4662.733382</td>\n",
       "      <td>43372.948389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4208.318142</td>\n",
       "      <td>3930.218580</td>\n",
       "      <td>5446.562407</td>\n",
       "      <td>8014.219914</td>\n",
       "      <td>3658.144368</td>\n",
       "      <td>5887.256261</td>\n",
       "      <td>6806.083194</td>\n",
       "      <td>4142.699459</td>\n",
       "      <td>4267.203600</td>\n",
       "      <td>4759.075375</td>\n",
       "      <td>51119.781315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3888.350691</td>\n",
       "      <td>3846.602754</td>\n",
       "      <td>5183.907182</td>\n",
       "      <td>7436.751298</td>\n",
       "      <td>3669.813283</td>\n",
       "      <td>5565.052033</td>\n",
       "      <td>6627.681069</td>\n",
       "      <td>4038.122900</td>\n",
       "      <td>4187.484000</td>\n",
       "      <td>4564.614294</td>\n",
       "      <td>49008.379392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4108.486962</td>\n",
       "      <td>4484.417434</td>\n",
       "      <td>5163.045673</td>\n",
       "      <td>7559.677321</td>\n",
       "      <td>3926.307934</td>\n",
       "      <td>5685.134009</td>\n",
       "      <td>6225.985349</td>\n",
       "      <td>3921.820116</td>\n",
       "      <td>4013.802000</td>\n",
       "      <td>4400.597774</td>\n",
       "      <td>49489.274575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4515.580422</td>\n",
       "      <td>4041.144875</td>\n",
       "      <td>5416.667457</td>\n",
       "      <td>8834.882136</td>\n",
       "      <td>4046.507613</td>\n",
       "      <td>5951.143558</td>\n",
       "      <td>6834.920104</td>\n",
       "      <td>5078.175921</td>\n",
       "      <td>4466.645500</td>\n",
       "      <td>4499.291151</td>\n",
       "      <td>53684.958746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5273.183988</td>\n",
       "      <td>4190.369657</td>\n",
       "      <td>6189.838469</td>\n",
       "      <td>9313.044036</td>\n",
       "      <td>4176.387447</td>\n",
       "      <td>6331.763843</td>\n",
       "      <td>8366.987540</td>\n",
       "      <td>4269.046174</td>\n",
       "      <td>4983.687000</td>\n",
       "      <td>4736.435904</td>\n",
       "      <td>57830.744070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5711.538596</td>\n",
       "      <td>2832.103219</td>\n",
       "      <td>4612.137004</td>\n",
       "      <td>10422.648988</td>\n",
       "      <td>1799.584141</td>\n",
       "      <td>3951.130302</td>\n",
       "      <td>5680.325548</td>\n",
       "      <td>2466.148751</td>\n",
       "      <td>5129.085000</td>\n",
       "      <td>4463.062521</td>\n",
       "      <td>47067.764032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6906.761140</td>\n",
       "      <td>7134.246191</td>\n",
       "      <td>10929.090479</td>\n",
       "      <td>13571.475418</td>\n",
       "      <td>7298.005995</td>\n",
       "      <td>7995.748875</td>\n",
       "      <td>11304.371647</td>\n",
       "      <td>8116.772377</td>\n",
       "      <td>7473.813000</td>\n",
       "      <td>7523.753491</td>\n",
       "      <td>88254.038601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6097.723153</td>\n",
       "      <td>6251.397279</td>\n",
       "      <td>9665.616068</td>\n",
       "      <td>11371.915256</td>\n",
       "      <td>5685.897410</td>\n",
       "      <td>7163.679662</td>\n",
       "      <td>9967.504627</td>\n",
       "      <td>6986.286160</td>\n",
       "      <td>6334.247600</td>\n",
       "      <td>5686.595199</td>\n",
       "      <td>75210.862372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5936.196322</td>\n",
       "      <td>6573.185582</td>\n",
       "      <td>8697.226316</td>\n",
       "      <td>10430.999778</td>\n",
       "      <td>5646.041251</td>\n",
       "      <td>6959.841448</td>\n",
       "      <td>8315.717458</td>\n",
       "      <td>6040.836447</td>\n",
       "      <td>5624.075700</td>\n",
       "      <td>5353.215461</td>\n",
       "      <td>69577.335747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>5213.389228</td>\n",
       "      <td>6035.497232</td>\n",
       "      <td>7902.289963</td>\n",
       "      <td>10766.941045</td>\n",
       "      <td>5617.949743</td>\n",
       "      <td>5380.294432</td>\n",
       "      <td>10822.738936</td>\n",
       "      <td>8741.049105</td>\n",
       "      <td>8585.327000</td>\n",
       "      <td>6677.128553</td>\n",
       "      <td>75742.605386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>5014.941636</td>\n",
       "      <td>4886.428074</td>\n",
       "      <td>7988.196339</td>\n",
       "      <td>10946.982574</td>\n",
       "      <td>5277.449924</td>\n",
       "      <td>5175.286138</td>\n",
       "      <td>11382.761888</td>\n",
       "      <td>6928.788711</td>\n",
       "      <td>8394.307000</td>\n",
       "      <td>5984.225171</td>\n",
       "      <td>71979.367094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4685.789839</td>\n",
       "      <td>4120.382805</td>\n",
       "      <td>4410.733220</td>\n",
       "      <td>10041.923116</td>\n",
       "      <td>2067.371890</td>\n",
       "      <td>3076.216048</td>\n",
       "      <td>6953.899715</td>\n",
       "      <td>3766.389294</td>\n",
       "      <td>7427.181000</td>\n",
       "      <td>5283.045256</td>\n",
       "      <td>51832.932335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.248108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4154.652278</td>\n",
       "      <td>4267.333932</td>\n",
       "      <td>6583.588947</td>\n",
       "      <td>9549.101372</td>\n",
       "      <td>4201.345590</td>\n",
       "      <td>4434.751308</td>\n",
       "      <td>10547.962700</td>\n",
       "      <td>6609.404624</td>\n",
       "      <td>7169.567400</td>\n",
       "      <td>5968.697339</td>\n",
       "      <td>63486.405472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>3857.897641</td>\n",
       "      <td>4103.857473</td>\n",
       "      <td>6274.687520</td>\n",
       "      <td>8255.779199</td>\n",
       "      <td>3924.272999</td>\n",
       "      <td>4177.535324</td>\n",
       "      <td>9569.668532</td>\n",
       "      <td>5484.447680</td>\n",
       "      <td>6643.356000</td>\n",
       "      <td>5512.063899</td>\n",
       "      <td>57803.566222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>3824.348997</td>\n",
       "      <td>5349.621996</td>\n",
       "      <td>5927.730414</td>\n",
       "      <td>8264.068984</td>\n",
       "      <td>4497.518631</td>\n",
       "      <td>4214.410605</td>\n",
       "      <td>8689.177902</td>\n",
       "      <td>5288.193240</td>\n",
       "      <td>5714.628400</td>\n",
       "      <td>5213.497878</td>\n",
       "      <td>56983.197065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>3772.552890</td>\n",
       "      <td>4108.950937</td>\n",
       "      <td>6039.235329</td>\n",
       "      <td>8437.337135</td>\n",
       "      <td>4343.472950</td>\n",
       "      <td>4023.589826</td>\n",
       "      <td>9130.450870</td>\n",
       "      <td>5723.362419</td>\n",
       "      <td>6335.138700</td>\n",
       "      <td>5006.810095</td>\n",
       "      <td>56920.901123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>3924.595310</td>\n",
       "      <td>4459.873069</td>\n",
       "      <td>6377.259414</td>\n",
       "      <td>9022.846871</td>\n",
       "      <td>4471.560799</td>\n",
       "      <td>4318.281577</td>\n",
       "      <td>9451.756835</td>\n",
       "      <td>5687.426422</td>\n",
       "      <td>5749.793000</td>\n",
       "      <td>5446.198215</td>\n",
       "      <td>58909.591479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>4097.525466</td>\n",
       "      <td>2835.989755</td>\n",
       "      <td>4145.209935</td>\n",
       "      <td>10039.210983</td>\n",
       "      <td>2045.552030</td>\n",
       "      <td>3117.880892</td>\n",
       "      <td>6371.202761</td>\n",
       "      <td>3582.391384</td>\n",
       "      <td>6761.441400</td>\n",
       "      <td>4832.357916</td>\n",
       "      <td>47828.762529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>5324.903650</td>\n",
       "      <td>7330.428833</td>\n",
       "      <td>9599.505054</td>\n",
       "      <td>13243.130272</td>\n",
       "      <td>7616.076761</td>\n",
       "      <td>6735.486192</td>\n",
       "      <td>13563.049386</td>\n",
       "      <td>9226.678566</td>\n",
       "      <td>10658.480000</td>\n",
       "      <td>7090.862208</td>\n",
       "      <td>90388.601392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>4992.422573</td>\n",
       "      <td>6269.335765</td>\n",
       "      <td>9091.569615</td>\n",
       "      <td>11481.103485</td>\n",
       "      <td>6135.664120</td>\n",
       "      <td>6087.241839</td>\n",
       "      <td>11890.357178</td>\n",
       "      <td>8292.151928</td>\n",
       "      <td>8273.997000</td>\n",
       "      <td>6744.458716</td>\n",
       "      <td>79258.302289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>4899.171080</td>\n",
       "      <td>6614.322677</td>\n",
       "      <td>8387.929174</td>\n",
       "      <td>10864.947607</td>\n",
       "      <td>5994.740921</td>\n",
       "      <td>5053.072887</td>\n",
       "      <td>10397.356752</td>\n",
       "      <td>7908.693575</td>\n",
       "      <td>7132.599000</td>\n",
       "      <td>6433.046021</td>\n",
       "      <td>73685.879816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>4479.264016</td>\n",
       "      <td>5320.681697</td>\n",
       "      <td>7859.467803</td>\n",
       "      <td>11059.489289</td>\n",
       "      <td>5316.122152</td>\n",
       "      <td>5073.856439</td>\n",
       "      <td>10183.213753</td>\n",
       "      <td>8451.363564</td>\n",
       "      <td>7865.006000</td>\n",
       "      <td>6144.978505</td>\n",
       "      <td>71753.443077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>4586.322775</td>\n",
       "      <td>4782.608744</td>\n",
       "      <td>7360.707932</td>\n",
       "      <td>10792.118165</td>\n",
       "      <td>4994.822482</td>\n",
       "      <td>4938.491404</td>\n",
       "      <td>10843.655809</td>\n",
       "      <td>6967.373759</td>\n",
       "      <td>7764.352000</td>\n",
       "      <td>5878.499621</td>\n",
       "      <td>68908.952742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>4446.348342</td>\n",
       "      <td>2934.398875</td>\n",
       "      <td>4038.903843</td>\n",
       "      <td>9906.893338</td>\n",
       "      <td>2012.750604</td>\n",
       "      <td>3030.731841</td>\n",
       "      <td>6663.896457</td>\n",
       "      <td>3839.242942</td>\n",
       "      <td>6824.866700</td>\n",
       "      <td>5316.732486</td>\n",
       "      <td>49014.765427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>3906.095211</td>\n",
       "      <td>4092.670546</td>\n",
       "      <td>5717.155088</td>\n",
       "      <td>9777.113586</td>\n",
       "      <td>3977.545251</td>\n",
       "      <td>4196.594408</td>\n",
       "      <td>9900.887575</td>\n",
       "      <td>5865.544546</td>\n",
       "      <td>7165.428000</td>\n",
       "      <td>5860.148945</td>\n",
       "      <td>60459.183380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>3786.133486</td>\n",
       "      <td>4017.805717</td>\n",
       "      <td>5744.375256</td>\n",
       "      <td>8620.478162</td>\n",
       "      <td>3852.728501</td>\n",
       "      <td>4003.904757</td>\n",
       "      <td>9247.850161</td>\n",
       "      <td>5392.265065</td>\n",
       "      <td>6388.514000</td>\n",
       "      <td>5814.462640</td>\n",
       "      <td>56868.517905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>3776.057640</td>\n",
       "      <td>5017.327983</td>\n",
       "      <td>5609.368631</td>\n",
       "      <td>8601.116822</td>\n",
       "      <td>4104.832942</td>\n",
       "      <td>3873.525437</td>\n",
       "      <td>8520.033795</td>\n",
       "      <td>5224.913094</td>\n",
       "      <td>5631.486000</td>\n",
       "      <td>5406.251321</td>\n",
       "      <td>55764.913504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>3701.543351</td>\n",
       "      <td>4155.381621</td>\n",
       "      <td>5621.820537</td>\n",
       "      <td>8256.533655</td>\n",
       "      <td>3849.910591</td>\n",
       "      <td>3857.727704</td>\n",
       "      <td>8971.163264</td>\n",
       "      <td>5890.586562</td>\n",
       "      <td>6209.763000</td>\n",
       "      <td>5830.192415</td>\n",
       "      <td>56344.622883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>3782.033448</td>\n",
       "      <td>4001.507758</td>\n",
       "      <td>5706.721259</td>\n",
       "      <td>8108.298185</td>\n",
       "      <td>4077.971237</td>\n",
       "      <td>3945.741744</td>\n",
       "      <td>9296.166432</td>\n",
       "      <td>5104.082701</td>\n",
       "      <td>5948.706500</td>\n",
       "      <td>5772.662940</td>\n",
       "      <td>55743.892247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>4206.353433</td>\n",
       "      <td>2679.429521</td>\n",
       "      <td>4132.804131</td>\n",
       "      <td>9580.301873</td>\n",
       "      <td>2027.489989</td>\n",
       "      <td>2983.708094</td>\n",
       "      <td>6570.800437</td>\n",
       "      <td>3381.496860</td>\n",
       "      <td>6920.119600</td>\n",
       "      <td>5014.186982</td>\n",
       "      <td>47496.690949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>5777.072901</td>\n",
       "      <td>6950.855119</td>\n",
       "      <td>9053.594415</td>\n",
       "      <td>11887.306002</td>\n",
       "      <td>7348.909395</td>\n",
       "      <td>6058.022162</td>\n",
       "      <td>14462.460051</td>\n",
       "      <td>9011.301879</td>\n",
       "      <td>10703.281000</td>\n",
       "      <td>7200.924160</td>\n",
       "      <td>88453.727335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>5231.826641</td>\n",
       "      <td>6019.527033</td>\n",
       "      <td>8550.100507</td>\n",
       "      <td>10547.283171</td>\n",
       "      <td>5916.736549</td>\n",
       "      <td>5122.596222</td>\n",
       "      <td>12411.801620</td>\n",
       "      <td>7410.610427</td>\n",
       "      <td>8381.512000</td>\n",
       "      <td>6305.517632</td>\n",
       "      <td>75897.511523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>4871.522631</td>\n",
       "      <td>6332.774044</td>\n",
       "      <td>7920.723981</td>\n",
       "      <td>10113.888283</td>\n",
       "      <td>5961.897794</td>\n",
       "      <td>5162.963689</td>\n",
       "      <td>11500.157129</td>\n",
       "      <td>6719.584642</td>\n",
       "      <td>7453.636700</td>\n",
       "      <td>5842.721550</td>\n",
       "      <td>71879.870462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>4616.802657</td>\n",
       "      <td>5389.226644</td>\n",
       "      <td>7996.062017</td>\n",
       "      <td>10665.673813</td>\n",
       "      <td>5061.086620</td>\n",
       "      <td>5021.390646</td>\n",
       "      <td>11695.859036</td>\n",
       "      <td>7922.431776</td>\n",
       "      <td>7888.610000</td>\n",
       "      <td>5974.443251</td>\n",
       "      <td>72231.586323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>5083.616595</td>\n",
       "      <td>5374.480205</td>\n",
       "      <td>8217.142946</td>\n",
       "      <td>12010.950993</td>\n",
       "      <td>5000.425974</td>\n",
       "      <td>5325.109168</td>\n",
       "      <td>13403.592858</td>\n",
       "      <td>7637.432271</td>\n",
       "      <td>8100.959500</td>\n",
       "      <td>6551.357368</td>\n",
       "      <td>76705.067851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1            2             3             4            5  \\\n",
       "0    5717.818209  6301.653071   9865.725643  10153.291251  5602.367520   \n",
       "1    5510.298604  6512.066582   8556.524297   9330.420316  5765.830248   \n",
       "2    5079.047790  5460.737801   7735.243498   9324.782816  4944.436392   \n",
       "3    4855.066339  4907.510546   8600.125698   9873.201129  5069.712080   \n",
       "4    4848.817431  2609.258951   4299.631053   9935.107310  1835.048437   \n",
       "5       0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "6    4364.450817  4004.262165   5161.439033   7940.504973  3824.709259   \n",
       "7    4031.301953  3947.826898   5158.895142   7462.205307  3727.959016   \n",
       "8    3944.842050  4649.660839   5124.796593   7195.689326  3997.489338   \n",
       "9    3894.189293  3881.791308   5029.780984   7370.564596  3713.124132   \n",
       "10   4245.188187  3914.496199   5753.720775   7714.182408  4080.789181   \n",
       "11   4983.633181  2532.131341   4116.094082   9505.201476  1778.062763   \n",
       "12      0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "13   5744.192988  6577.690528   7323.494665  11638.913468  6713.288646   \n",
       "14   5223.222718  5930.723979   8106.196403   9930.915505  5657.912371   \n",
       "15   5362.314867  6181.119323   8337.048882   9310.429981  5723.656718   \n",
       "16   5163.339575  5152.720556   7665.836171   9095.553007  4884.909327   \n",
       "17   5257.620845  4781.019769   7538.104661   9534.606713  4964.245910   \n",
       "18   5379.716069  2459.275038   4088.689027   9704.708709  1711.137049   \n",
       "19      0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "20   4208.318142  3930.218580   5446.562407   8014.219914  3658.144368   \n",
       "21   3888.350691  3846.602754   5183.907182   7436.751298  3669.813283   \n",
       "22   4108.486962  4484.417434   5163.045673   7559.677321  3926.307934   \n",
       "23   4515.580422  4041.144875   5416.667457   8834.882136  4046.507613   \n",
       "24   5273.183988  4190.369657   6189.838469   9313.044036  4176.387447   \n",
       "25   5711.538596  2832.103219   4612.137004  10422.648988  1799.584141   \n",
       "26      0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "27   6906.761140  7134.246191  10929.090479  13571.475418  7298.005995   \n",
       "28   6097.723153  6251.397279   9665.616068  11371.915256  5685.897410   \n",
       "29   5936.196322  6573.185582   8697.226316  10430.999778  5646.041251   \n",
       "..           ...          ...           ...           ...          ...   \n",
       "905  5213.389228  6035.497232   7902.289963  10766.941045  5617.949743   \n",
       "906  5014.941636  4886.428074   7988.196339  10946.982574  5277.449924   \n",
       "907  4685.789839  4120.382805   4410.733220  10041.923116  2067.371890   \n",
       "908     0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "909  4154.652278  4267.333932   6583.588947   9549.101372  4201.345590   \n",
       "910  3857.897641  4103.857473   6274.687520   8255.779199  3924.272999   \n",
       "911  3824.348997  5349.621996   5927.730414   8264.068984  4497.518631   \n",
       "912  3772.552890  4108.950937   6039.235329   8437.337135  4343.472950   \n",
       "913  3924.595310  4459.873069   6377.259414   9022.846871  4471.560799   \n",
       "914  4097.525466  2835.989755   4145.209935  10039.210983  2045.552030   \n",
       "915     0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "916  5324.903650  7330.428833   9599.505054  13243.130272  7616.076761   \n",
       "917  4992.422573  6269.335765   9091.569615  11481.103485  6135.664120   \n",
       "918  4899.171080  6614.322677   8387.929174  10864.947607  5994.740921   \n",
       "919  4479.264016  5320.681697   7859.467803  11059.489289  5316.122152   \n",
       "920  4586.322775  4782.608744   7360.707932  10792.118165  4994.822482   \n",
       "921  4446.348342  2934.398875   4038.903843   9906.893338  2012.750604   \n",
       "922     0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "923  3906.095211  4092.670546   5717.155088   9777.113586  3977.545251   \n",
       "924  3786.133486  4017.805717   5744.375256   8620.478162  3852.728501   \n",
       "925  3776.057640  5017.327983   5609.368631   8601.116822  4104.832942   \n",
       "926  3701.543351  4155.381621   5621.820537   8256.533655  3849.910591   \n",
       "927  3782.033448  4001.507758   5706.721259   8108.298185  4077.971237   \n",
       "928  4206.353433  2679.429521   4132.804131   9580.301873  2027.489989   \n",
       "929     0.000000     0.000000      0.000000      0.000000     0.000000   \n",
       "930  5777.072901  6950.855119   9053.594415  11887.306002  7348.909395   \n",
       "931  5231.826641  6019.527033   8550.100507  10547.283171  5916.736549   \n",
       "932  4871.522631  6332.774044   7920.723981  10113.888283  5961.897794   \n",
       "933  4616.802657  5389.226644   7996.062017  10665.673813  5061.086620   \n",
       "934  5083.616595  5374.480205   8217.142946  12010.950993  5000.425974   \n",
       "\n",
       "               6             7            8             9           10  \\\n",
       "0    7176.216977  10341.561739  6505.311482   6302.959000  5714.657222   \n",
       "1    6921.244257   8090.852354  5673.728950   5184.818400  5539.029505   \n",
       "2    6314.656802   8066.825115  6234.547054   5388.263000  5616.178584   \n",
       "3    6927.614117   8099.700803  5206.362083   5703.361300  5606.811352   \n",
       "4    3765.943200   4538.281949  2510.754229   4922.026000  4541.323872   \n",
       "5       0.000000      0.000000     0.000000      0.181546     0.000000   \n",
       "6    5972.879755   6844.887051  4286.980709   4508.520000  4817.428118   \n",
       "7    5616.944218   6807.330886  4192.341320   4212.599000  4569.376346   \n",
       "8    5247.771443   6372.850673  3895.344289   3837.493400  4551.669918   \n",
       "9    5554.787497   6780.353349  4827.428066   4421.266000  4520.857199   \n",
       "10   5715.102832   7574.897096  3990.749414   4977.212400  4764.123412   \n",
       "11   3646.093786   4818.921211  2425.080131   5132.261000  4502.695003   \n",
       "12      0.000000      0.000000     0.000000      0.121323     0.000000   \n",
       "13   7280.665828  10721.421378  7750.308633   6943.394500  6657.925012   \n",
       "14   7011.165911   9260.975655  6376.083705   5284.628400  5405.284997   \n",
       "15   6988.189735   8047.107928  5940.518205   5022.631300  5270.986395   \n",
       "16   6215.657925   7918.644043  6436.209779   5071.469000  4981.103498   \n",
       "17   6586.677830   8398.576603  5148.807489   5526.992000  5377.504432   \n",
       "18   3568.620140   4415.173737  2419.843968   4963.051300  4662.733382   \n",
       "19      0.000000      0.000000     0.000000      0.146441     0.000000   \n",
       "20   5887.256261   6806.083194  4142.699459   4267.203600  4759.075375   \n",
       "21   5565.052033   6627.681069  4038.122900   4187.484000  4564.614294   \n",
       "22   5685.134009   6225.985349  3921.820116   4013.802000  4400.597774   \n",
       "23   5951.143558   6834.920104  5078.175921   4466.645500  4499.291151   \n",
       "24   6331.763843   8366.987540  4269.046174   4983.687000  4736.435904   \n",
       "25   3951.130302   5680.325548  2466.148751   5129.085000  4463.062521   \n",
       "26      0.000000      0.000000     0.000000      0.140618     0.000000   \n",
       "27   7995.748875  11304.371647  8116.772377   7473.813000  7523.753491   \n",
       "28   7163.679662   9967.504627  6986.286160   6334.247600  5686.595199   \n",
       "29   6959.841448   8315.717458  6040.836447   5624.075700  5353.215461   \n",
       "..           ...           ...          ...           ...          ...   \n",
       "905  5380.294432  10822.738936  8741.049105   8585.327000  6677.128553   \n",
       "906  5175.286138  11382.761888  6928.788711   8394.307000  5984.225171   \n",
       "907  3076.216048   6953.899715  3766.389294   7427.181000  5283.045256   \n",
       "908     0.000000      0.000000     0.000000     -0.248108     0.000000   \n",
       "909  4434.751308  10547.962700  6609.404624   7169.567400  5968.697339   \n",
       "910  4177.535324   9569.668532  5484.447680   6643.356000  5512.063899   \n",
       "911  4214.410605   8689.177902  5288.193240   5714.628400  5213.497878   \n",
       "912  4023.589826   9130.450870  5723.362419   6335.138700  5006.810095   \n",
       "913  4318.281577   9451.756835  5687.426422   5749.793000  5446.198215   \n",
       "914  3117.880892   6371.202761  3582.391384   6761.441400  4832.357916   \n",
       "915     0.000000      0.000000     0.000000      0.194832     0.000000   \n",
       "916  6735.486192  13563.049386  9226.678566  10658.480000  7090.862208   \n",
       "917  6087.241839  11890.357178  8292.151928   8273.997000  6744.458716   \n",
       "918  5053.072887  10397.356752  7908.693575   7132.599000  6433.046021   \n",
       "919  5073.856439  10183.213753  8451.363564   7865.006000  6144.978505   \n",
       "920  4938.491404  10843.655809  6967.373759   7764.352000  5878.499621   \n",
       "921  3030.731841   6663.896457  3839.242942   6824.866700  5316.732486   \n",
       "922     0.000000      0.000000     0.000000      0.057824     0.000000   \n",
       "923  4196.594408   9900.887575  5865.544546   7165.428000  5860.148945   \n",
       "924  4003.904757   9247.850161  5392.265065   6388.514000  5814.462640   \n",
       "925  3873.525437   8520.033795  5224.913094   5631.486000  5406.251321   \n",
       "926  3857.727704   8971.163264  5890.586562   6209.763000  5830.192415   \n",
       "927  3945.741744   9296.166432  5104.082701   5948.706500  5772.662940   \n",
       "928  2983.708094   6570.800437  3381.496860   6920.119600  5014.186982   \n",
       "929     0.000000      0.000000     0.000000      0.142046     0.000000   \n",
       "930  6058.022162  14462.460051  9011.301879  10703.281000  7200.924160   \n",
       "931  5122.596222  12411.801620  7410.610427   8381.512000  6305.517632   \n",
       "932  5162.963689  11500.157129  6719.584642   7453.636700  5842.721550   \n",
       "933  5021.390646  11695.859036  7922.431776   7888.610000  5974.443251   \n",
       "934  5325.109168  13403.592858  7637.432271   8100.959500  6551.357368   \n",
       "\n",
       "            Total  \n",
       "0    73681.562097  \n",
       "1    67084.813473  \n",
       "2    64164.719037  \n",
       "3    64849.465475  \n",
       "4    43806.192311  \n",
       "5        0.181546  \n",
       "6    51726.061900  \n",
       "7    49726.780208  \n",
       "8    48817.607877  \n",
       "9    49994.142538  \n",
       "10   52730.461908  \n",
       "11   43440.174202  \n",
       "12       0.121323  \n",
       "13   77351.295677  \n",
       "14   68187.109661  \n",
       "15   66184.003382  \n",
       "16   62585.443120  \n",
       "17   63114.156440  \n",
       "18   43372.948389  \n",
       "19       0.146441  \n",
       "20   51119.781315  \n",
       "21   49008.379392  \n",
       "22   49489.274575  \n",
       "23   53684.958746  \n",
       "24   57830.744070  \n",
       "25   47067.764032  \n",
       "26       0.140618  \n",
       "27   88254.038601  \n",
       "28   75210.862372  \n",
       "29   69577.335747  \n",
       "..            ...  \n",
       "905  75742.605386  \n",
       "906  71979.367094  \n",
       "907  51832.932335  \n",
       "908     -0.248108  \n",
       "909  63486.405472  \n",
       "910  57803.566222  \n",
       "911  56983.197065  \n",
       "912  56920.901123  \n",
       "913  58909.591479  \n",
       "914  47828.762529  \n",
       "915      0.194832  \n",
       "916  90388.601392  \n",
       "917  79258.302289  \n",
       "918  73685.879816  \n",
       "919  71753.443077  \n",
       "920  68908.952742  \n",
       "921  49014.765427  \n",
       "922      0.057824  \n",
       "923  60459.183380  \n",
       "924  56868.517905  \n",
       "925  55764.913504  \n",
       "926  56344.622883  \n",
       "927  55743.892247  \n",
       "928  47496.690949  \n",
       "929      0.142046  \n",
       "930  88453.727335  \n",
       "931  75897.511523  \n",
       "932  71879.870462  \n",
       "933  72231.586323  \n",
       "934  76705.067851  \n",
       "\n",
       "[935 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Phase 2 data set which is comprised of both aggregate SKU data and forecasts\n",
    "dc_pred=pd.DataFrame(bm_dict[0][0])\n",
    "# sku_pred=pd.read_csv('C:\\\\Users\\\\lengada1\\\\NCSU\\\\prediction_skus.csv')\n",
    "sku_pred=pd.read_csv('./prediction_skus.csv')\n",
    "sku_pred=sku_pred.iloc[:,1:]\n",
    "X2=pd.concat([sku_pred,dc_pred,pd.DataFrame(X)],axis=1)\n",
    "sku_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=range(0,33)\n",
    "new_cols =  ['' + str(i) for i in rng]\n",
    "X2.columns = new_cols[:32]\n",
    "std2= preprocessing.StandardScaler().fit(X2)\n",
    "X2 = std2.transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLP2():\n",
    "    mlp=models.Sequential()\n",
    "    mlp.add(Dense(40, input_dim=X2.shape[1], activation='relu'))\n",
    "    #mlp.add(Dense(20, activation='relu'))\n",
    "    mlp.add(Dense(30, activation='relu'))\n",
    "    mlp.add(Dense(10, activation='relu'))    \n",
    "    mlp.add(Dense(1, activation='relu'))\n",
    "    mlp.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "    return mlp\n",
    "\n",
    "MLP2 = KerasRegressor(build_fn=create_MLP2,\n",
    "                               epochs=600,\n",
    "                               batch_size=20,\n",
    "                               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_models=[];\n",
    "rf2_models=(cross_val_score(RF,X2,y,cv=cv, scoring ='mean_absolute_error').mean().round(0) )\n",
    "\n",
    "gb2_models=[];\n",
    "gb2_models=(cross_val_score(GB,X2,y,cv=cv, scoring ='mean_absolute_error').mean().round(0)  )\n",
    "   \n",
    "\n",
    "xg2_models=[];\n",
    "xg2_models=(cross_val_score(XG,X2,y,cv=cv, scoring ='mean_absolute_error').mean().round(0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp2_models=[];\n",
    "mlp2_models=(cross_val_score(MLP2,X2,y,cv=cv, scoring='mean_absolute_error').mean().round(0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>XG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1273.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MLP      RF      GB      XG\n",
       "0  1273.0  1210.0  1185.0  1076.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae2=-pd.DataFrame(np.column_stack((mlp2_models,rf2_models,gb2_models,xg2_models)) )\n",
    "mae2=mae2.rename(columns = {0:'MLP',1:'RF',2:'GB',3:'XG'})\n",
    "mae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>XG</th>\n",
       "      <th>Best</th>\n",
       "      <th>min</th>\n",
       "      <th>error reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29376.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>XG</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1273.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>XG</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MLP      RF      GB      XG Best     min  error reduction\n",
       "0  29376.0  3306.0  3220.0  3208.0   XG  3208.0            0.665\n",
       "1   1273.0  1210.0  1185.0  1076.0   XG  1076.0            0.665"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using forecasted data and no empirical sales data, the best performaning model is selected based on Train/Test. \n",
    "## NOTE this improvement is not the true delta.  Only a final forecast between Stage 1 vs 2 will tell. \n",
    "\n",
    "best2=mae2.idxmin(axis=1)\n",
    "best2.astype('category')\n",
    "mae2[\"Best\"]=best2\n",
    "both_mae=pd.concat([mae,mae2],axis=0)\n",
    "both_mae.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Phase 1 & 2 DC Models compared based on Test set MAE scores. \n",
    "both_mae['min']=both_mae.min(axis=1)\n",
    "both_mae['error reduction']= ((both_mae['min'][0]-both_mae['min'][1])/both_mae['min'][0] ).round(3)\n",
    "both_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm2_dict={}\n",
    "for sku in range(0,1):\n",
    "        if  mae2[\"Best\"][0]==\"RF\":\n",
    "            bm2_dict[sku]=RF_final(X2,y);\n",
    "                    \n",
    "        elif mae2[\"Best\"][0]==\"NN\":\n",
    "            bm2_dict[sku]=MLP_final(X2,y);\n",
    "                                \n",
    "        elif mae2[\"Best\"][0]==\"GB\":\n",
    "            bm2_dict[sku]=GB_final(X2,y); \n",
    "                        \n",
    "        elif mae2[\"Best\"][0]==\"XG\":\n",
    "            bm2_dict[sku]=XG_final(X2,y);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DC_Phase1</th>\n",
       "      <th>DC_Phase2</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72276.0</td>\n",
       "      <td>72624.0</td>\n",
       "      <td>72552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64639.0</td>\n",
       "      <td>64623.0</td>\n",
       "      <td>64297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63063.0</td>\n",
       "      <td>63171.0</td>\n",
       "      <td>64112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65082.0</td>\n",
       "      <td>64899.0</td>\n",
       "      <td>65006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43302.0</td>\n",
       "      <td>43239.0</td>\n",
       "      <td>43300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-108.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50399.0</td>\n",
       "      <td>50441.0</td>\n",
       "      <td>50984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48025.0</td>\n",
       "      <td>47986.0</td>\n",
       "      <td>48246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47117.0</td>\n",
       "      <td>45865.0</td>\n",
       "      <td>45400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47812.0</td>\n",
       "      <td>47265.0</td>\n",
       "      <td>46978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51814.0</td>\n",
       "      <td>51643.0</td>\n",
       "      <td>51511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43586.0</td>\n",
       "      <td>42550.0</td>\n",
       "      <td>42506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-144.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>72734.0</td>\n",
       "      <td>72252.0</td>\n",
       "      <td>71624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>66857.0</td>\n",
       "      <td>67995.0</td>\n",
       "      <td>68454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>65423.0</td>\n",
       "      <td>65817.0</td>\n",
       "      <td>66359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>61757.0</td>\n",
       "      <td>60867.0</td>\n",
       "      <td>60730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63515.0</td>\n",
       "      <td>63457.0</td>\n",
       "      <td>63379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43451.0</td>\n",
       "      <td>41695.0</td>\n",
       "      <td>41514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-353.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49418.0</td>\n",
       "      <td>48816.0</td>\n",
       "      <td>48742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>47642.0</td>\n",
       "      <td>47712.0</td>\n",
       "      <td>47741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48516.0</td>\n",
       "      <td>48676.0</td>\n",
       "      <td>48958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55565.0</td>\n",
       "      <td>57591.0</td>\n",
       "      <td>58657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>59834.0</td>\n",
       "      <td>60897.0</td>\n",
       "      <td>60284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47965.0</td>\n",
       "      <td>48977.0</td>\n",
       "      <td>49258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>88540.0</td>\n",
       "      <td>88624.0</td>\n",
       "      <td>87665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74724.0</td>\n",
       "      <td>74227.0</td>\n",
       "      <td>74556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69899.0</td>\n",
       "      <td>70438.0</td>\n",
       "      <td>70827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>76932.0</td>\n",
       "      <td>76041.0</td>\n",
       "      <td>75256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>71662.0</td>\n",
       "      <td>71327.0</td>\n",
       "      <td>71053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>49787.0</td>\n",
       "      <td>49593.0</td>\n",
       "      <td>49651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>182.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>63597.0</td>\n",
       "      <td>64895.0</td>\n",
       "      <td>65461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>57149.0</td>\n",
       "      <td>57980.0</td>\n",
       "      <td>57315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>57864.0</td>\n",
       "      <td>58640.0</td>\n",
       "      <td>58514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>57034.0</td>\n",
       "      <td>58209.0</td>\n",
       "      <td>58747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>60673.0</td>\n",
       "      <td>60557.0</td>\n",
       "      <td>59787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>48026.0</td>\n",
       "      <td>47231.0</td>\n",
       "      <td>46215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>78.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>88875.0</td>\n",
       "      <td>88829.0</td>\n",
       "      <td>88715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>77791.0</td>\n",
       "      <td>79513.0</td>\n",
       "      <td>80477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>74063.0</td>\n",
       "      <td>73517.0</td>\n",
       "      <td>73330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>72112.0</td>\n",
       "      <td>72736.0</td>\n",
       "      <td>72878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>67582.0</td>\n",
       "      <td>65148.0</td>\n",
       "      <td>64608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>47703.0</td>\n",
       "      <td>48666.0</td>\n",
       "      <td>49229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>218.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>61520.0</td>\n",
       "      <td>62324.0</td>\n",
       "      <td>62773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>55923.0</td>\n",
       "      <td>56076.0</td>\n",
       "      <td>56076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>56188.0</td>\n",
       "      <td>55414.0</td>\n",
       "      <td>53958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>55452.0</td>\n",
       "      <td>56172.0</td>\n",
       "      <td>56591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>55634.0</td>\n",
       "      <td>55227.0</td>\n",
       "      <td>54317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>46640.0</td>\n",
       "      <td>45176.0</td>\n",
       "      <td>44903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>87511.0</td>\n",
       "      <td>86674.0</td>\n",
       "      <td>86899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>76953.0</td>\n",
       "      <td>76069.0</td>\n",
       "      <td>74693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>73031.0</td>\n",
       "      <td>73206.0</td>\n",
       "      <td>72885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>73430.0</td>\n",
       "      <td>73333.0</td>\n",
       "      <td>73389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>78824.0</td>\n",
       "      <td>83173.0</td>\n",
       "      <td>83695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DC_Phase1  DC_Phase2  Sales\n",
       "0      72276.0    72624.0  72552\n",
       "1      64639.0    64623.0  64297\n",
       "2      63063.0    63171.0  64112\n",
       "3      65082.0    64899.0  65006\n",
       "4      43302.0    43239.0  43300\n",
       "5       -108.0        9.0      0\n",
       "6      50399.0    50441.0  50984\n",
       "7      48025.0    47986.0  48246\n",
       "8      47117.0    45865.0  45400\n",
       "9      47812.0    47265.0  46978\n",
       "10     51814.0    51643.0  51511\n",
       "11     43586.0    42550.0  42506\n",
       "12      -144.0       13.0      0\n",
       "13     72734.0    72252.0  71624\n",
       "14     66857.0    67995.0  68454\n",
       "15     65423.0    65817.0  66359\n",
       "16     61757.0    60867.0  60730\n",
       "17     63515.0    63457.0  63379\n",
       "18     43451.0    41695.0  41514\n",
       "19      -353.0       10.0      0\n",
       "20     49418.0    48816.0  48742\n",
       "21     47642.0    47712.0  47741\n",
       "22     48516.0    48676.0  48958\n",
       "23     55565.0    57591.0  58657\n",
       "24     59834.0    60897.0  60284\n",
       "25     47965.0    48977.0  49258\n",
       "26       114.0       31.0      0\n",
       "27     88540.0    88624.0  87665\n",
       "28     74724.0    74227.0  74556\n",
       "29     69899.0    70438.0  70827\n",
       "..         ...        ...    ...\n",
       "905    76932.0    76041.0  75256\n",
       "906    71662.0    71327.0  71053\n",
       "907    49787.0    49593.0  49651\n",
       "908      182.0       23.0      0\n",
       "909    63597.0    64895.0  65461\n",
       "910    57149.0    57980.0  57315\n",
       "911    57864.0    58640.0  58514\n",
       "912    57034.0    58209.0  58747\n",
       "913    60673.0    60557.0  59787\n",
       "914    48026.0    47231.0  46215\n",
       "915       78.0       -0.0      0\n",
       "916    88875.0    88829.0  88715\n",
       "917    77791.0    79513.0  80477\n",
       "918    74063.0    73517.0  73330\n",
       "919    72112.0    72736.0  72878\n",
       "920    67582.0    65148.0  64608\n",
       "921    47703.0    48666.0  49229\n",
       "922      218.0        4.0      0\n",
       "923    61520.0    62324.0  62773\n",
       "924    55923.0    56076.0  56076\n",
       "925    56188.0    55414.0  53958\n",
       "926    55452.0    56172.0  56591\n",
       "927    55634.0    55227.0  54317\n",
       "928    46640.0    45176.0  44903\n",
       "929       38.0       10.0      0\n",
       "930    87511.0    86674.0  86899\n",
       "931    76953.0    76069.0  74693\n",
       "932    73031.0    73206.0  72885\n",
       "933    73430.0    73333.0  73389\n",
       "934    78824.0    83173.0  83695\n",
       "\n",
       "[935 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tier_pred=pd.concat([bm_dict[0][0],bm2_dict[0][0],y],axis=1)\n",
    "tier_pred.columns = ['DC_Phase1', 'DC_Phase2',\"Sales\"]\n",
    "# tier_pred.to_csv('C:\\\\Users\\\\lengada1\\\\NCSU\\\\DC_tier_predictions.csv')\n",
    "tier_pred.to_csv('./DC_tier_predictions.csv')\n",
    "tier_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# END NOTEBOOK\n",
    "bm_dict[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    \"\"\"\n",
    "    Saves the model as a file. \n",
    "    - Keras models: saved as .json and .h5 files\n",
    "    - scikit-learn models: saved as .pickle files\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(model) is KerasRegressor:\n",
    "        \n",
    "        model_json = model.model.to_json()\n",
    "        with open('{}.json'.format(filename), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        model.model.save_weights('{}.h5'.format(filename))        \n",
    "    else:\n",
    "        pickle_out = open('{}.pickle'.format(filename), \"wb\")\n",
    "        pickle.dump(model, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "\n",
    "# Save model to disk\n",
    "filename=\"NCSU_DC\"\n",
    "model = bm_dict[0][1]\n",
    "save_model(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from disk\n",
    "def load_pickled_model(path_to_model):\n",
    "    loaded_model = pickle.load(open(path_to_model, 'rb'))\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "def load_keras_model(path_to_json, path_to_weights_h5):\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(path_to_json, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path_to_weights_h5)\n",
    "    \n",
    "    # wrap Sequential obj as a KerasRegressor to allow scikit-learn compatibility\n",
    "    wrapped_loaded_model = KerasRegressor(build_fn=create_MLP, epochs=400, batch_size=20, verbose=0)\n",
    "    \n",
    "    return wrapped_loaded_model\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads a given file as a model\n",
    "    - .pickle files: loaded as scikit-learn models\n",
    "    - .json and .h5 files: loaded together to create Keras models\n",
    "    \"\"\"\n",
    "    \n",
    "    loaded_model = None\n",
    "    \n",
    "    try:\n",
    "        loaded_model = load_pickled_model(\"{}.pickle\".format(filename))\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        loaded_model = load_keras_model(\"{}.json\".format(filename), \"{}.h5\".format(filename))\n",
    "        \n",
    "    return loaded_model\n",
    "\n",
    "loaded_model = load_model(\"NCSU_DC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV Score</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3208.0</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CV Score Family\n",
       "0    3208.0    MLP"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model on test data\n",
    "scores=[]\n",
    "model_family=[]\n",
    "    \n",
    "# Identify the model family\n",
    "if isinstance(loaded_model, RandomForestRegressor):\n",
    "    model_family.append('RF')\n",
    "else:\n",
    "    model_family.append('MLP')\n",
    "\n",
    "# Obtain the cross validation score\n",
    "score = -cross_val_score(loaded_model,X,y,cv=cv, scoring ='mean_absolute_error').mean().round(0)\n",
    "scores.append(score)        \n",
    "\n",
    "loaded_model_scores = pd.DataFrame({\n",
    "    'CV Score':scores,\n",
    "    'Family':model_family\n",
    "})\n",
    "\n",
    "loaded_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
